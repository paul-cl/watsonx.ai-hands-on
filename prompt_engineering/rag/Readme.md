# 프롬프트 엔지니어링
## 프롬프트 엔지니어링이란?
프롬프트 엔지니어링 기법은 AI 모델, 특히 openAI의 GPT-4, Google Gemini 또는 IBM Granite와 같은 대규모 언어 모델(LLM)에 제공되는 프롬프트, 입력 쿼리 또는 지침을 설계하고 구성하는 데 사용되는 전략입니다. 이러한 기술의 목적은 생성형 AI(gen AI) 시스템이 정확하고 관련성이 높으며 상황에 맞는 응답을 생성하도록 안내하여 사용자가 원하는 아웃풋을 효과적으로 얻을 수 있도록 하는 것입니다.

고급 머신 러닝 알고리즘을 기반으로 구축된 대규모 언어 모델은 인간과 유사한 텍스트를 이해하고 생성할 수 있습니다. 프롬프트 엔지니어링은 이 기능을 활용하여 모델이 요약, 번역, 창의적 글쓰기 또는 문제 해결과 같은 복잡한 작업을 보다 정밀하게 수행하는 데 도움이 되는 입력을 생성합니다. 사용자는 다양한 프롬프트 구조를 실험함으로써 LLM의 동작에 영향을 주어 다양한 애플리케이션에서 성능을 최적화할 수 있습니다.

생성형 AI가 다양한 영역에서 계속해서 중요한 역할을 함에 따라, 생성형 AI의 잠재력을 최대한 활용하고 특정 요구 사항을 효율적으로 충족하도록 AI 모델을 맞춤화하려면 이제 프롬프트 엔지니어링을 이해하는 것이 필수입니다.


# Prompting Labs 
## Lab 1 — Zero-shot Prompting (기본 프롬프트)

목표
- 예시 없이(Zero-shot) 모델이 주어진 작업을 수행할 때 출력 품질을 관찰하고, 프롬프트 수정 없이 얻은 응답의 장단점을 평가할 수 있다.
- 명료성, 핵심포인트 보존(정확성), 간결성 측면에서 결과를 비교·평가한다.

실습용 예시 문장
```
인공지능은 의료 분야에서 환자 치료 결과를 개선하고, 행정 업무를 자동화하는 데 점점 더 많이 활용되고 있습니다. 의료 분야에서 인공지능의 활용은 의사와 환자 모두에게 많은 이점을 제공할 수 있습니다. 예를 들어, 의사는 인공지능을 사용하여 의료 데이터를 분석하고, 환자의 상태를 실시간으로 모니터링할 수 있습니다. 또한, 인공지능은 의료 비용을 절감하고, 의료 서비스의 질을 향상시키는 데 도움이 될 수 있습니다. 인공지능은 의료 분야에서 다양한 응용 분야를 가지고 있으며, 의료 산업의 미래를 결정하는 데 중요한 역할을 할 것입니다. 인공지능 기술의 발전은 의료 산업의 발전에 큰 영향을 미칠 것입니다. 이러한 발전은 의료 산업의 미래를 밝게 할 것입니다
```

실습 과제
1. 단문 요약(기본)
   - 위 기본 프롬프트 그대로 모델에 입력하고 한 문장 요약을 받는다.
        ```
        제시한 글을 한 문장으로 요약해줘.
        ```
   - 목표: Zero-shot 기본 성능 관찰
   - 답안 예시
        ```
        "인공지능은 의료 분야에서 환자 치료 결과를 개선하고, 행정 업무를 자동화하는 데 점점 더 많이 활용되고 있습니다."
        ```

2. 명확성 개선 요구
   - 모델에 "더 명확하게, 전문용어는 피하고 15단어 이내로 요약해 주세요." 라고 추가 요구하고 비교한다.
        ```
        더 명확하게, 전문용어는 피하고 15단어 이내로 요약해 주세요.
        ```
   - 목표: 제약을 추가했을 때 표현 변화 관찰

3. 핵심 포인트 강조
   - 모델에 "핵심 포인트(치료 개선, 행정 자동화)를 쉼표로 구분하여 포함해 한 문장으로 요약해 주세요."라고 요청한다.
        ```
        핵심 포인트(치료 개선, 행정 자동화)를 쉼표로 구분하여 포함해 한 문장으로 요약해 주세요.
        ```
   - 목표: 핵심 요소 보존 여부 확인

4. 대상 독자 바꾸기
   - 두 가지 버전 생성을 요청하도록 프롬프트 생성
        ```
        두 가지 버전 생성: a) 일반인 대상(쉽게), b) 의료 전문가 대상(전문용어 포함). 각 한 문장으로 요약해 주세요.
        ```
   - 목표: 관점(페르소나)에 따른 어조·용어 차이 관찰

5. 도메인 비교 확장 실습 (응용)
   - 원문을 금융 도메인 문장으로 바꿔 같은 요약 요청: 예) "인공지능은 금융 분야에서 리스크 관리와 고객 서비스 자동화에..."  
   - 교육 도메인 문장도 동일하게 만들어 요약하고 세 결과를 비교한다.
   - 목표: 도메인 전환 시 모델의 핵심 포인트 포착 능력 평가

프롬프트 평가 체크리스트
- 명료성: 문장이 이해하기 쉬운가?
- 핵심성: 원문의 주요 아이디어들이 포함되었는가? (치료 개선, 행정 자동화)
- 간결성: 불필요한 단어 없이 간단한가?
- 적합성(대상 독자): 요청한 톤/어휘를 맞췄는가?

프롬프트 변형 예시
- "한 문장으로 요약하되 핵심 단어를 괄호로 표시하세요."
- "요약문을 소셜 미디어 헤드라인(한 줄) 스타일로 작성하세요."
- "공식 보고서 형식으로 12단어 내외로 요약하세요."

사용 사례
- 교육: 학생에게 긴 문단 핵심 전달 연습  
- 회의: 의사결정용 회의록 자동 요약 테스트




## Lab 2 — Few-shot Prompting 

목표
- 몇 가지 예시(Few-shot)를 제공해 모델이 분류 패턴을 학습하도록 유도하고, 예시 수/형태가 성능에 미치는 영향을 관찰한다.
- 정확도뿐만 아니라 일관성, 오답 유형(혼동되는 경우)을 분석한다.

실습용 기본 예시와 프롬프트
- 예시 1: "이 제품 정말 좋아요!" → 긍정  
- 예시 2: "서비스가 형편없어요." → 부정  
- 실습 프롬프트(기본):  
  이 리뷰의 감정을 분류해 주세요: "영화가 정말 재미있었어요!"

실습 과제
1. 기본 Few-shot 분류
   - 위 두 예시와 함께 기본 프롬프트를 모델에 입력하고 레이블(긍정/부정)을 얻는다.
   - 목표: 예시 기반 분류의 기본 동작 관찰
   - 예시 프롬프트:
     ```
     예시: "이 제품 정말 좋아요!" -> 긍정
     예시: "서비스가 형편없어요." -> 부정
     태스크: "영화가 정말 재미있었어요!"의 감정을 분류해 주세요.
     ```

2. 예시 수 증가 실험
   - 예시를 4~6개로 늘리고(중립, 강한긍정 등 포함) 동일한 입력을 분류해 결과 변화를 비교한다.
        ```
        예시 1: "이 제품 정말 좋아요!" -> 긍정
        예시 2: "서비스가 형편없어요." -> 부정
        예시 3: "그럭저럭 괜찮네요." -> 중립
        예시 4: "정말 최고의 제품이에요!" -> 강한 긍정
        예시 5: "다신 사지 않을 거예요." -> 강한 부정
        예시 6: "생각보다 만족스러웠어요." -> 약한 긍정
        ```
   - 목표: 예시 수/다양성에 따른 성능 향상 여부 확인

3. 라벨 세분화 (중립 포함) 및 혼동 분석
   - 라벨을 긍정/중립/부정으로 확장하고, 애매한 문장(예: "생각보다 괜찮았어요")을 분류해 모델의 혼동 유형을 관찰한다.
        ```
        문장을 '긍정/중립/부정' 중 하나로만 라벨링해 주세요:
        "생각보다 괜찮았어요."
        ```
   - 목표: 라벨 스킴 변경 시 오류 유형 파악

4. 근거(정당화) 요구
   - 분류 결과와 함께 간단한 근거(핵심 단어 또는 문장 부분)를 요구한다.
     ```
     분류 결과와 왜 그렇게 판단했는지 한 문장으로 설명해 주세요.
     ```
   - 목표: 모델이 어떤 단서를 사용했는지 투명성 확인

5. 도메인·언어 변형 실험
   - 동일한 구조로 제품 리뷰, 영화 리뷰, 고객지원 채팅 로그 등 도메인을 바꿔 테스트
   - 영어/한국어 혼합 입력을 넣어 다국어 처리 성능도 확인
   - 목표: 도메인·언어 변환 시 일반화 능력 평가

프롬프트 평가 체크리스트
- 정확도: 레이블이 옳은가?
- 일관성: 동일한 프롬프트 반복 시 결과가 안정적인가?
- 해석 가능성: 근거를 통해 판단 근거가 합리적인가?
- 라벨 균형: 특정 레이블로 편향되지 않았는가?

프롬프트 변형 예시
- "아래 예시들을 참고해, 라벨(긍정/부정/중립)로 분류하고 근거 1문장을 덧붙여 주세요."
- "감정 강도(약/중/강)도 함께 표기하세요."
- "모델이 오답을 자주 내는 경우, 더 많은 반례(negative examples)를 추가하세요."

운영 팁
- 평가를 위해 소규모의 라벨링된 검증 세트(20–50문장)를 준비해 실험마다 동일 세트로 비교한다.
- 예시 편향을 피하려면 예시 문장들의 길이, 어조, 도메인을 다양화한다.
- 결과를 표(프롬프트, 예시 수, 정확도, 메모)로 기록해 재현성을 유지한다.

사용 사례
- 고객 피드백 자동 라우팅(긍정/부정 분류)  
- 소셜 미디어 모니터링 대시보드용 감성분석 파이프라인


## Lab 3 — Chain-of-Thought Prompting (단계적 사고)

목표
- 모델이 복잡한 문제를 풀 때 내부 추론 과정을 단계별로 생성하도록 유도하여 출력의 투명성(transparency)과 정확성을 평가한다.
- 단계적 사고(Chain-of-Thought)가 결과 정확도에 미치는 영향, 출력 길이·명료성·오류 유형을 비교·분석한다.

실습용 기본 프롬프트(예시)
- 간단 수학 문제(기본):  
    ```
    기차가 60km를 1.5시간 동안 달렸습니다. 평균 속도는 몇 km/h인가요?
    ```
- 응용(논리/코드):  
  "다음 코드의 문제를 단계별로 찾아 수정 방법을 제안해 주세요:"
    ```python
    # 짝수 합을 구하려고 만든 함수 — 의도: 1..n 사이 짝수 합 반환
    def sum_even_up_to(n):
        total = 0
        for i in range(2, n, 2):  # 버그: range 끝값이 n이면 n 포함되지 않음
            total += i
        return total

    print(sum_even_up_to(10))  # 예상 30, 실제? 확인해보기
    ```

실습 과제
1. 기본(비단계적) 응답
   - 프롬프트: 
        ```
        기차가 60km를 1.5시간 동안 달렸습니다. 평균 속도는 몇 km/h인가요? 답만 알려주세요.
        ```
   - 목표: Zero-shot 스타일로 간단 정답만 얻었을 때 성능 관찰

2. 단계별 사고(자유 서술)
   - 프롬프트: 
        ```
        단계별로 생각하며 계산 과정을 보여주고 최종 답을 제시해 주세요.
        ```
   - 목표: 모델이 각 단계(단위, 계산 과정)를 명시하는지 확인하고 정확성 검증

3. 축약된 단계(간결한 CoT)
   - 프롬프트: 
        ```
        3단계 이내로 핵심 단계만 적고 최종 답을 주세요.
        ```
   - 목표: 단계 수 제한 시에도 정확성 유지 여부와 가독성 평가

4. 검토 및 오류 탐지
   - 프롬프트: 
        ```
        이전 답변을 검토하고 실수가 있으면 수정한 이유와 함께 올바른 답을 제시해 주세요.
        ```
   - 목표: 모델의 자기검증(self-check) 능력 확인 — 오류 발견·수정 사례 수집

5. 응용 연습(논리 퍼즐 / 코드 디버깅)
   - 예: "논리 퍼즐: A는 B보다 빨리 출발했고, C는 A보다 늦게 도착했다. 누가 가장 먼저 도착했는지 단계별로 추론해 주세요."
   - 예: "Python 코드(간단한 버그 포함)를 주고, 단계별로 문제 원인과 수정안을 제시해 주세요."
   - 목표: 수학/논리/코드 영역에서 CoT의 유효성 비교

프롬프트 평가 체크리스트
- 정확성: 최종 답이 올바른가?
- 단계의 명확성: 각 단계가 논리적으로 연결되는가?
- 불필요한 추론(허상): 근거 없는 정보가 섞였는가?
- 효율성: 단계 수 대비 가독성·간결성은 적절한가?
- 자기검증: 모델이 스스로 오류를 찾아 수정했는가?

실습 운영 팁
- 동일 문제에 대해 "답만" vs "단계별"을 모두 실행해 차이를 표로 기록한다.
- 온도(temperature)를 낮추면 일관성 증가, 높이면 다양한 추론경로 관찰 가능 — 비교 실험 권장.
- Chain-of-Thought는 민감한 사실을 만들어낼 수 있으니(factual hallucination) 사실성 검증 절차를 두자.
- 코드 디버깅 실습 시, 문제 재현 가능한 최소 예제로 테스트한다.

프롬프트 변형 예시
- "단계마다 계산 식을 보여주고, 각 단계 옆에 간단한 설명(한 문장)을 붙여 주세요."
- "먼저 결론을 제시한 뒤, 그 결론에 이르는 3단계 근거를 적어 주세요."
- "검토 단계에서 '가능한 오류'와 '오류 확률(높음/보통/낮음)'을 함께 적어 주세요."

사용 사례 (심화)
- 여러 추론 경로 생성 후 비교(간단한 트리 오브 사고와 병행)
- CoT 응답을 자동 검증하는 간단한 테스트 스크립트 작성(정답 체크리스트)
- CoT를 이용한 복합 태스크(문제풀이 → 요약 → 평가) 체이닝 실험




## Lab 4 — Tree-of-Thought Prompting (다중 사고 경로) 확장판

목표
- 모델이 여러 가능한 사고 경로(해결 아이디어)를 동시에 탐색하도록 하여 다양한 대안들을 생성하고, 그중 최적안을 선택하는 과정을 경험한다.
- 각 경로의 장단점·리스크를 비교 분석하고, 선택 기준을 명시해 의사결정 투명성을 확보한다.

실습용 기본 프롬프트 예시
- 기본 프롬프트:  
    ```
    원격 근무 팀워크를 향상시킬 3가지 아이디어를 제시하고, 각 아이디어의 장단점과 예상 리스크를 적어 주세요. 그 후 최적의 방법을 선택하고 이유(선택 기준 포함)를 설명해 주세요.
    ```

실습 과제
1. 다중 아이디어 생성(탐색)
   - 프롬프트: 위 기본 프롬프트로 모델에게 4~6개의 서로 다른 접근법(프로세스 개선, 툴 도입, 문화 활동 등)을 생성하게 한다.
   - 목표: 다양한 해결 경로(폭넓은 탐색) 확보

2. 각 경로의 분석(평가)
   - 프롬프트: 각 아이디어에 대해 '장점', '단점', '실행 난이도(낮음/중간/높음)', '예상 효과(높음/중간/낮음)'을 표나 짧은 항목으로 정리하도록 요청한다.
        ```
        예시 프롬프트
        아래 아이디어 목록에 대해 각 항목마다 '장점', '단점', '실행 난이도(낮음/중간/높음)', '예상 효과(높음/중간/낮음)'를 간단히 2~3줄로 정리해 주세요.
        아이디어 목록: A: 정기 화상 회의, B: 주간 업무 대시보드, C: 온라인 팀 빌딩 이벤트
        ```
   - 목표: 비교 가능한 근거 마련

3. 점수화 및 랭킹
   - 프롬프트: 선택 기준(비용, 실행 속도, 팀 수용성, 효과)을 명시하고 각 아이디어를 1–10 점으로 평가한 뒤 총점 기준으로 정렬하게 한다.
        ```
        간단 점수화 예제 프롬프트
        아래 아이디어들에 대해 선택 기준(비용, 실행 속도, 팀 수용성, 효과)을 각각 1–10점으로 평가하고, 총점을 계산해 총점 기준으로 내림차순 정렬해 주세요. 각 아이디어별로 1문장 근거도 덧붙여 주세요.
        아이디어 목록: A, B, C
        ```
        ```
        표 형식 예제 프롬프트
        각 아이디어에 대해 비용, 실행 속도, 팀 수용성, 효과 점수(1–10), 가중합(위 가중치 사용)을 마크다운 표로 작성하고, 총점 기준으로 상위 3개에 대해 한 문장씩 선택 이유를 적어 주세요.
        아이디어 목록: A, B, C
        ```
   - 목표: 정량적·정성적 기준을 결합한 의사결정 연습

4. 최종 선택 및 근거 제시
   - 프롬프트: 
        ```
        가장 좋은 방법을 선택하고, 선택 이유와 예상 추진 계획(3단계)을 적어 주세요.
        ```
   - 목표: 선택의 타당성 및 실행 로드맵 도출

5. 대안 경로 심화(검증·통제)
   - 프롬프트: "만약 예산이 50%로 줄어들면 우선순위와 실행 계획을 어떻게 바꾸겠는가?" 등 제약을 바꿔 재평가한다.
        ```
        예산이 50%로 감소한 상황에서 각 아이디어별로 비용 절감 방안 3가지를 제안하고, 우선순위를 바꾼 실행계획(3단계)을 작성해 주세요.
        ```
   - 목표: 제약하에서의 견고성(robustness) 평가

평가 체크리스트
- 다양성: 생성된 아이디어들이 충분히 다른가?
- 비교가능성: 장단점/점수화로 합리적 비교가 가능한가?
- 근거성: 선택 근거가 명확하고 설득력 있는가?
- 견고성: 제약(예산/시간/인력)을 바꿔도 타당한 결과를 내는가?
- 실행가능성: 제안된 실행 계획이 구체적이고 현실적인가?


프롬프트 변형 예시
- "각 아이디어마다 예상 KPI(측정 지표)를 2개씩 제안해 주세요."
- "팀 규모(10명)와 예산(월 $1,000)을 고려해 우선순위를 다시 제안하세요."
- "아이디어 3개를 합쳐 하이브리드 솔루션을 만들고, 통합 장단점을 설명하세요."

사용 사례
- 제품 출시 전략, 고객 세분화 전략 등 의사결정 시나리오에 적용해 복수 대안 비교 실습
- Tree-of-Thought 출력들을 자동으로 평가하는 간단한 스코어보드(예: 비용·효과·리스크) 제작
- 여러 번 생성한 사고 경로를 집계해 '가장 자주 등장하는 핵심 아이디어'를 추출하고 실험군으로 테스트



## Lab 5 — Meta Prompting (프롬프트 생성 AI) 확장판

목표
- 모델이 '좋은 프롬프트'를 스스로 생성하도록 하여, 프롬프트 설계 역량을 자동화·확장할 수 있음을 확인한다.
- 생성된 메타 프롬프트의 품질(명확성, 제약 준수, 결과 일관성)을 평가하고, 실제 태스크에 적용해 성능 차이를 측정한다.

실습용 기본 태스크
- 원래 태스크: 긴 기술 기사를 요약하라.
- 메타 태스크(기본): "위 태스크를 더 잘 수행할 수 있는 프롬프트를 만들어 주세요."

실습 과제
1. 메타 프롬프트 생성(기본)
   - 프롬프트: "긴 기술 기사를 핵심 요약(3문장)으로 만드는 더 나은 프롬프트를 작성해 주세요."
   - 목표: 모델이 요약 목표·출력 형식·제약(길이, 독자)을 포함한 프롬프트를 생성하는지 확인

2. 제약 추가 및 정교화
   - 프롬프트: 생성된 메타 프롬프트에 '대상 독자(전문가/일반인)', '단어수 제한', '포맷(마크다운, 불릿)', '중요 문장 인용 여부' 같은 제약을 추가해 개선안 생성
   - 목표: 제약이 포함될 때 프롬프트 품질 개선 여부 관찰

3. 메타 프롬프트 적용 및 비교
   - 실행: 동일한 원문(짧은 기술 기사 200-400단어)에 대해   
     a) 기존 간단 프롬프트(Zero-shot)  
     b) 사람이 설계한 개선 프롬프트  
     c) 모델이 생성한 메타 프롬프트  
     를 각각 적용해 요약을 생성하고 품질을 비교
   - 목표: 메타 프롬프트의 실효성 검증

4. 평가·피드백 루프(반복 개선)
   - 프롬프트: "생성된 요약을 평가하고, 핵심 누락·모호성·길이 문제를 근거로 메타 프롬프트를 한 번 더 개선해 주세요."
   - 목표: 자동화된 프롬프트-생성→적용→평가→개선 루프 실습

5. 템플릿·자동화 적용(심화)
   - 프롬프트: "다양한 문서 유형(기술 기사, 블로그, 정책문서)에 대해 재사용 가능한 메타 프롬프트 템플릿 3가지를 제안하세요."
   - 목표: 실무 파이프라인에 적용 가능한 프롬프트 템플릿 구축

평가 체크리스트
- 명료성: 메타 프롬프트가 목표와 출력 형식을 명확히 제시하는가?
- 제약 반영성: 길이·톤·출력 포맷 등 요구사항을 제대로 포함했는가?
- 일관성: 반복 적용 시 출력 품질이 안정적인가?
- 효율성: 사람이 만든 프롬프트 대비 개선 효과(시간/품질)는 있는가?
- 일반화: 다른 도메인(정책/교육/금융)에 적용 가능한가?

메타 프롬프트 예시
- 간단형:
  "긴 기술 기사를 3문장 요약으로 만들어 주세요. 핵심 주장 1개, 주요 근거 1개 포함."
- 제약형:
  "일반 대중을 위한 50단어 이내 요약을 작성하되, 기술용어는 괄호로 설명하세요. 마크다운 불릿 3개로 출력."
- 구조형:
  "요약문(한 문단), 핵심 포인트(3개 불릿), 추가 읽을거리(한줄) 순으로 출력하는 프롬프트를 만들어 주세요."
- 검증 포함형:
  "생성된 요약의 핵심 문장 2개에 대해 원문 근거(원문에서 발췌한 문장)를 함께 제시하도록 프롬프트를 작성하세요."


사용 사례
- 사용자 유형별(관리자, 엔지니어, 고객) 맞춤 메타 프롬프트 생성 실험
- Prompt-ensemble: 여러 메타 프롬프트로 후보 요약 다수 생성 → 랭킹·집계(합의) 방식 적용
- 메타 프롬프트의 자동 튜닝: 성능 지표(Rouge 등)를 피드백으로 받아 프롬프트를 자동 변형하는 간단한 루프 구현

예시 워크플로(짧게)
1) 원문 입력 → 2) 메타 프롬프트 생성 → 3) 요약 생성 → 4) 평가 지표 계산 → 5) 메타 프롬프트 개선(반복)



## Lab 6 — Prompt Chaining (프롬프트 체이닝)

목표
- 다단계 프롬프트(입력 → 중간 출력 → 후속 입력)를 연결해 복합 작업을 안정적으로 수행하도록 학습한다.
- 각 단계의 출력 품질이 다음 단계 성능에 미치는 영향을 관찰하고, 체인 설계(단계 분해, 중간 검증)를 통한 오류 누적 방지 전략을 연습한다.

실습용 기본 프롬프트(체인 시나리오)
- 원문: 짧은 기사(200~400단어)나 회의록
    ```
    생성형 AI는 입력된 프롬프트를 기반으로 텍스트, 이미지, 음악 등 새로운 콘텐츠를 자동으로 만들어내는 인공지능 기술이다. 대부분의 모델은 트랜스포머 기반의 디코더 구조를 사용하며, 대규모 텍스트·시각 데이터를 사전 학습한 뒤 조건부 샘플링이나 디퓨전 과정을 통해 출력을 생성한다. 주요 특징으로는(1) 높은 창의성과 다양성, (2) 사전 학습 지식의 광범위한 활용, (3) 실시간 응답이 가능한 빠른 처리 속도를 들 수 있다. 활용 방안은 챗봇·문서 요약·코드 자동 생성, 이미지·영상 합성·디자인 시안 제안, 맞춤형 교육·마케팅 콘텐츠 제작 등으로, 기업의 생산성 향상과 개인화 서비스 제공에 크게 기여한다. 그러나 주의해야 할 점도 많다. 첫째, 학습 데이터에 포함된 편향·저작권 문제가 그대로 전이될 위험이 있다. 둘째, 허위 정보·가짜 뉴스 생성 등 악용 가능성이 존재한다. 셋째, 모델이 예측하지 못한 민감한 정보를 노출하거나 보안 취약점을 만들 수 있다. 따라서 데이터 출처 검증·저작권 관리, 출력물 사실 검증 절차, 윤리·보안 가이드라인 수립, 지속적인 모니터링과 업데이트가 필수적이다. 이러한 책임 있는 운영을 통해 생성형 AI는 창의적 가치를 높이며 안전하게 사회에 융합될 수 있다.
    ```
- 전체 목표(예): "다음 글에서 3가지 핵심 주제를 추출하고, 각 주제에 대해 한 문장 요약, 후속질문 1개, 발표용 슬라이드(3불릿)를 만들어 주세요."

실습 과제 
1. 핵심 주제 추출 (Step 1 → Step 2 입력)
   - 프롬프트 예시:
     ```
     이 글에서 3가지 핵심 주제를 추출해 번호로 나열해 주세요.
     ```
   - 목표: 중복 없이 대표 주제 도출(체인 첫 출력의 품질이 중요)

2. 각 주제에 대한 한 문장 요약 (Step 2 → Step 3 입력)
   - 프롬프트 예시:
     ```
     위에서 추출한 주제 각각에 대해 일반인도 이해할 수 있는 한 문장 요약을 작성해 주세요.
     ```
   - 목표: 주제별 핵심 정리(간결성·정확성 확인)

3. 주제별 후속 질문 생성 (Step 3 → Step 4 입력)
   - 프롬프트 예시:
     ```
     각 주제에 대해 토론을 심화할 수 있는 후속 질문을 한 개씩 만들어 주세요.
     ```
   - 목표: 문서 활용성 확장(토론·조사 포인트 확보)

4. 발표용 자료(슬라이드) 생성 (Step 4 → Step 5 입력)
   - 프롬프트 예시:
     ```
     각 주제별로 발표용 슬라이드 한 장 분량(제목 + 3불릿 요약)을 만들어 주세요.
     ```
   - 목표: 중간 출력으로부터 실무적 산출물 생성 여부 검증

5. QA/피드백 루프 및 검증 (검사·수정)
   - 프롬프트 예시:
     ```
     전체 체인 출력을 검토하고, 누락된 핵심 포인트 또는 논리적 오류가 있으면 지적하고 수정된 버전을 제시해 주세요.
     ```
   - 목표: 체인에서 발생한 누적 오류(드리프트)를 잡아내고 보정

평가 체크리스트
- 전달력: 각 단계 출력이 다음 단계 입력 요건(형식/정보)을 충족하는가?
- 정보보존: 원문 핵심이 체인 끝까지 유지되는가?
- 오류누적: 단계별로 생긴 오차가 누적되었는가?
- 재현성: 동일 체인 반복 시 유사한 결과가 나오는가?
- 실무적용성: 최종 산출물(슬라이드/질문)이 실제로 사용 가능한 수준인가?


프롬프트 변형 예시
- "Step 1 결과를 JSON 배열로 반환하세요: [{id:1, topic:'...'}, ...]"
- "각 슬라이드의 3불릿은 '문제, 핵심 인사이트, 권장 액션' 구조로 작성하세요."
- "검증 단계에서 원문과 불일치하는 요약 문장이 있으면 원문 인용과 함께 수정하세요."

사용 사례
- 자동 파이프라인: Step1→Step2...을 간단한 스크립트로 연결해 배치 처리(예: Python) 구현
- RAG 결합: 중간 단계에 외부 문서 검색 결과를 넣어 보완된 요약/질문 생성 실험
- 성능 측정: 단계별 정량 지표(키워드 보존율, 길이 오차, ROUGE 등)를 수집해 체인 설계 최적화

예제 워크플로
1) 원문 입력 → 2) 주제 추출 → 3) 주제별 요약 → 4) 후속질문 생성 → 5) 슬라이드 생성 → 6) 검증 및 수정



## Lab 7 — RAG Integration (검색 증강 생성) 

목표
- 외부 문서(검색 결과)를 활용해 사실 기반의 답변을 생성하고, 모델의 허위정보 생성(hallucination)을 줄이는 워크플로를 이해한다.
- 검색(검색기/임베딩) → 문서 선정 → 생성(답변) 단계에서 각각의 역할과 실패 모드를 파악하고 품질 검증 절차를 설계한다.

실습용 기본 프롬프트(시스템/사용자 예시)
- 시스템(지시): "아래에 제공된 검색 결과와 회사 정책 문서만 사용해서 답변하세요. 출처(문서 ID 또는 제목)를 문장 끝에 괄호로 표기하세요. 근거가 없으면 '정보 없음'으로 응답하세요."
- 사용자(질문): "회사 내부 개인정보 처리 지침에서 제3자 데이터 공유 시 필요한 절차는 무엇인가요?"

실습 과제 (3–5단계)
1. RAG 기본 흐름 실습 — 검색 결과만 사용
   - 준비: 샘플 문서 3~5개(정책·가이드·FAQ)를 텍스트로 준비.
   - 프롬프트: 시스템 지시와 사용자 질문을 합쳐 모델에 전달하고, 모델이 반드시 제공된 문서에서만 인용하도록 요구.
   - 목표: 모델이 외부 지식 없이 답을 생성하는지 확인(허용 여부 판단).

2. 발췌 인용 연습(출처 표기)
   - 프롬프트: "각 핵심 진술 뒤에 출처 문서명(또는 ID)을 괄호로 표기하고, 해당 근거 문장(원문 발췌)을 함께 제시하세요."
   - 목표: 답변의 traceability 확보(어떤 문서가 근거인지 확인).

3. 불확실성 처리 및 보수적 답변
   - 프롬프트: "문서에 근거가 없거나 모호한 부분은 '정보 없음' 또는 '추가 확인 필요'로 표기하고, 추가 확인이 필요한 항목을 1~2개 제안하세요."
   - 목표: 모델의 추측을 억제하고 안전한 응답 처리 절차 경험.

4. 문서 랭킹·요약 기반 응답(검색 결과 정제)
   - 프롬프트: "검색 결과 5개를 중요도 순으로 정렬하고, 상위 2개 문서의 관련 문단을 요약해 최종 답변을 작성하세요."
   - 목표: 다수 문서에서 중복·상충 정보를 통합하는 방법 연습

5. 파이프라인 구현 및 평가(자동화)
   - 작업: 간단한 RAG 파이프라인 구현(문서 인덱싱 → 검색(쿼리) → 상위 K개 스니펫을 모델 입력으로 사용 → 응답 및 출처 표기).
   - 평가: 정성(체크리스트) + 정량(정확도, 출처 일치율)로 성능 측정.
   - 목표: RAG 구성 요소별(검색 품질, 스니펫 길이, 프롬프트 설계)가 결과에 미치는 영향 파악

평가 체크리스트
- 출처 일치성: 모델이 인용한 내용이 실제 문서에 있는가?
- 사실성(accuracy): 제시된 사실이 문서 근거와 일치하는가?
- 보수성: 근거가 없을 때 모델이 추측을 자제하는가?
- 응답 완전성: 질문에 대한 핵심 절차·규정이 빠짐없이 제시되었는가?
- 추적 가능성: 답변의 각 주장에 출처가 표기되어 있는가?

프롬프트 변형 예시
- 보수적 응답(권장)
  ```
  시스템: 제공된 문서만 사용해 답하세요. 근거가 문서에 없으면 '정보 없음'이라고 답하세요.
  사용자: "문서(POLICY_A)에서 개인정보 파기 절차를 알려주세요."
  ```
- 발췌 + 출처(표 형식)
  ```
  요청: 답변을 항목별로 작성하고, 각 항목 옆에 (문서명: 문단 번호) 형식으로 출처를 표기하세요. 가능하면 근거 문장 1개를 붙이세요.
  ```
- JSON 출력(자동화 용)
  ```
  반환 형식: [{"claim":"...","source":"docX","quote":"...","confidence":"높음/중간/낮음"}, ...]
  ```
- 불확실성 표시
  ```
  답변 마지막에 '확인 필요 항목' 리스트를 포함하고, 각 항목에 대해 권장 확인 방법을 1문장으로 제시하세요.
  ```

사용 사례
- RAG + 체인(Chain-of-Thought): 검색 스니펫을 기반으로 단계적 추론을 유도해 복잡 질의 대응
- 사용자 쿼리 수정(쿼리 리라이팅) 자동화: 질문→검색쿼리 최적화→검색→생성으로 피드백 루프 구성
- 평가 대시보드: 출처 일치율·정확도·응답시간을 시각화하여 파이프라인 튜닝




## Lab 8 — Directional / Persona Prompting (관점·스타일 제어) 

목표
- 모델이 요청된 역할(페르소나)·관점·톤에 맞춰 답변을 조정하는 능력을 평가한다.
- 동일한 사실을 다른 이해관계자 관점으로 표현했을 때 논점·어조·단어 선택이 어떻게 달라지는지 비교·분석한다.
- 실무 커뮤니케이션(정책·마케팅·기술 문서)에서 적절한 톤 선택과 리스크 관리 방법을 연습한다.

실습용 기본 프롬프트(예시)
- 기본 요청: "재생 가능 에너지의 장점을 다음 역할로 설명해 주세요: a) 환경 과학자 b) 석탄 산업 경영자"
- 출력 형식 요구(선택): 각 역할별 3문장 이내, 핵심 포인트 2개 불릿, 권장 어조(예: 설득적/중립적/방어적)

실습 과제 
1. 기본 페르소나 비교
   - 프롬프트:
     ```
     역할 A(환경 과학자)와 역할 B(석탄 산업 경영자) 각각으로 재생 가능 에너지의 장점을 3문장 이내로 설명해 주세요.
     ```
   - 목표: 관점별 핵심 논점·어조 차이 확인

2. 어조·청중 조정
   - 프롬프트:
     ```
     같은 내용을 (1) 일반 대중 대상(쉽고 친근하게), (2) 경영진 대상(비용·ROI 중심), (3) 기술자 대상(기술적 근거 포함)으로 각 역할별 한 문장씩 재작성해 주세요.
     ```
   - 목표: 대상 독자에 따른 어휘·논거 차이 관찰

3. 반대 관점(이의 제기) 시뮬레이션
   - 프롬프트:
     ```
     석탄 산업 경영자 입장에서 재생 가능 에너지의 단점 3가지를 제시하고, 환경 과학자 입장에서 각 단점에 대해 반박 논거를 한 문장씩 작성해 주세요.
     ```
   - 목표: 쟁점별 대응 전략과 설득 포인트 정리 연습

4. 메시지 안전성·규제 고려
   - 프롬프트:
     ```
     정책 발표용 메시지(공식 톤, 40단어 이내)를 작성하되, 과장된 수치나 근거 없는 주장 없이 신중하게 표현하고, 필요 시 출처 표기를 권장하세요.
     ```
   - 목표: 준법·사실성·톤 관리 연습

5. A/B 스타일 테스트 설계
   - 프롬프트:
     ```
     역할 A와 역할 B의 메시지 중 어느 쪽이 내부 이해관계자(경영진) 설득에 더 효과적인지 A/B 테스트 설계를 제안하세요(가설, 측정지표, 샘플링, 성공 기준).
     ```
   - 목표: 메시지 선정 근거를 데이터로 검증하는 방법 학습

프롬프트 평가 체크리스트
- 적합성: 요청한 페르소나·톤을 잘 반영했는가?
- 논점 명확성: 핵심 주장이 분명한가(근거 포함 여부)?
- 어휘·정서: 대상 독자에 맞는 어휘·정서(톤)를 사용했는가?
- 사실성: 근거 없는 주장은 없는가(과장·허위여부 확인)?
- 실용성: 제안된 대응·메시지가 실제로 활용 가능한가?

프롬프트 변형 예시
- "환경 과학자(중립, 근거 중심): 3문장, 연구 근거 1개 포함"
- "석탄 산업 경영자(방어적, 비용 중심): 2문장, 비용·일자리 영향 강조"
- "경영진용 요약: 한 문장, 권장 액션 포함"
- "대중용 소셜카피: 30자 이내, 친근한 어투"


사용 사례
- 기업 커뮤니케이션: 위기관리 메시지(언론 대응) 역할극 시뮬레이션
- 마케팅: 페르소나별 광고 카피 생성 → CTR 테스트 설계
- 정책 토론: 이해관계자별 포지션 문서 자동 생성 후 합의 도출 워크숍 진행


## Lab 9 — Reflective / Self-consistency Prompting (자기 검토) 

목표
- 모델이 스스로 생성한 답변을 검토하고 개선하도록 유도하여 응답의 정확성·명료성·일관성을 높이는 방법을 실습한다.
- 1차 생성 → 검토(근거·모호성·누락점 지적) → 개선된 재생성의 워크플로를 통해 모델의 자기검증 능력을 평가한다.

실습용 기본 프롬프트(예시)
- 질문: "물은 왜 생명에 필수적인가요?"
- 기본 지시: 먼저 답을 작성한 뒤, 이전 답변을 검토해 명확성·정확성·간결성을 개선한 수정안을 작성하라.

실습 과제 
1. 1차 응답 생성(기본)
   - 프롬프트:
     ```
     물은 왜 생명에 필수적인가요? 2~3문장으로 답해 주세요.
     ```
   - 목표: Zero-shot 응답의 기본 품질 관찰

2. 자기검토 지시(명확성·정확성)
   - 프롬프트:
     ```
     이전 답변을 검토하고, 핵심 누락·모호한 표현·잘못된 정보가 있으면 지적하세요. 각 지적마다 수정된 문장을 제시해 주세요.
     ```
   - 목표: 모델이 스스로 오류·모호점을 찾아 수정하는지 확인

3. 근거·출처 요구(검증성)
   - 프롬프트:
     ```
     수정된 답변의 핵심 주장 2개에 대해 한 줄씩 근거를 제시하거나 신뢰 가능한 출처 예시를 덧붙여 주세요.
     ```
   - 목표: 주장에 대한 근거 제시 능력 확인

4. 대체 표현(간결성·대상별 조정)
   - 프롬프트:
     ```
     동일한 내용을 (a) 어린이용(쉽게), (b) 과학자용(간결·정확하게) 두 형식으로 각각 한 문장씩 재작성해 주세요.
     ```
   - 목표: 검토 후 여러 톤·길이로 적응하는 능력 테스트

5. 자동화 루프 테스트(반복 개선)
   - 작업: 1) 생성 → 2) 검토 지시 → 3) 개선안 적용 → 4) 다시 검토(최대 2회) 흐름을 반복하고, 각 단계별 변경 기록을 비교 분석
   - 목표: 반복 검토로 품질 향상이 이루어지는지 정량·정성으로 평가

프롬프트 평가 체크리스트
- 검출력: 모델이 스스로 오류·모호점을 찾아내는가?
- 개선성: 검토 후 답변 품질(명료성·정확성·간결성)이 실제로 향상되었는가?
- 근거 제시: 중요한 주장에 대해 합리적 근거를 제시했는가?
- 일관성: 여러 번의 검토 반복에서 답변이 안정적으로 수렴하는가?
- 과도한 자신감 회피: 불확실한 항목은 '확인 필요'로 표시했는가?

프롬프트 변형 예시
- "이전 답변에서 사실관계가 틀릴 가능성이 있는 문장을 찾아 '가능한 오류'로 표시하고, 수정 이유를 한 줄로 적어 주세요."
- "각 수정안 옆에 신뢰도(높음/중간/낮음)를 표기하세요."
- "검토 시 외부 검증 방법(참고문헌, 검색어 예시)을 1~2개 제안하세요."



사용 사례
- 코드 리뷰: 간단 코드 스니펫에 대해 1차 진단 → 검토 → 수정 제안 루프 적용
- 문서 품질 향상: 초안 보고서→모델 검토 지시→수정안 적용→최종 검토 파이프라인 구축
- Self-consistency 실험: 동일 문제에 대해 여러 독립적 추론을 생성하고 합의(consensus)를 도출해 최종 답을 선택하는 방식 적용


# 요약
- 본 랩은 Zero-shot, Few-shot, CoT, ToT, Meta Prompting, Prompt Chaining, RAG, Persona, Self-review 등 주요 프롬프트 기법을 실습을 통해 비교·평가하도록 설계되었다.
- 핵심 목표는 프롬프트 설계가 출력 품질에 미치는 영향을 이해하고, 실무 적용 가능한 검증·피드백 루프를 구축하는 것이다.

