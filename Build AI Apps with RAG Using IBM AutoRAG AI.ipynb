{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b855cc",
   "metadata": {},
   "source": [
    "# IBM Auto AI RAG 사용하기\n",
    "IBM Auto AI RAG를 사용하여 RAG를 만들고 배포한 AI 서비스를 LangChain과 결합하여 최종 응답을 처리합니다.\n",
    "이 노트북은 IBM Auto AI를 통해 구축된 RAG(Retrieval-Augmented Generation) 시스템을 LangChain과 통합하여 AI 애플리케이션을 구축하는 방법을 안내합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12e5d8",
   "metadata": {},
   "source": [
    "# 라이브러리 설치하기\n",
    "Lab에서 Auto AI RAG를 사용하기 위해서는 아래의 라이브러리를 설치해야 합니다.\n",
    "이 셀에서는 필요한 라이브러리들을 설치합니다. `langchain`, `langchain_openai`, `langchain_community`, 그리고 `langchain-ibm`을 설치합니다.  `TOKENIZERS_PARALLELISM` 환경 변수를 설정하여 병렬 처리 관련 경고를 억제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "!pip install langchain==0.3.0\n",
    "!pip install langchain --upgrade\n",
    "\n",
    "!pip install langchain_openai\n",
    "!pip install langchain_community\n",
    "\n",
    "!pip install -U langchain-ibm\n",
    "!pip install ibm-watsonx-ai==1.3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf8aa8",
   "metadata": {},
   "source": [
    "라이브러리 설치가 완료 되었으면 노트북 커널을 Restart 합니다.\n",
    "메뉴에서 `kernel > restart` 를 실행합니다.\n",
    "설치된 라이브러리를 적용하기 위해 노트북 커널을 재시작해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a699ad3",
   "metadata": {},
   "source": [
    "# IBM AutoAI RAG 서비스를 적용한 RAG 시스템 구현\n",
    "이 섹션에서는 배포한 IBM AutoAI RAG 서비스를 파이썬 코드를 사용하여 호출하는 방법을 설명합니다.\n",
    "이 코드는 IBM Cloud watsonx.ai를 사용하여 IBM AutoAI RAG 서비스를 생성 및 배포한 후에 실행해야 합니다. 이 코드는 IBM AutoAI RAG 서비스의 REST API를 호출하여 모델을 생성하고 예측을 수행하는 방법을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import json\n",
    "\n",
    "def convert_to_documents(json_data):\n",
    "    \"\"\"\n",
    "    JSON 데이터를 LangChain Document 객체로 변환하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        json_data (str or dict): JSON 문자열 또는 파싱된 JSON 객체\n",
    "        \n",
    "    Returns:\n",
    "        list: LangChain Document 객체의 리스트\n",
    "    \"\"\"\n",
    "    # JSON 데이터가 문자열인 경우 파싱\n",
    "    if isinstance(json_data, str):\n",
    "        try:\n",
    "            data = json.loads(json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"JSON 파싱 오류: {e}\")\n",
    "    else:\n",
    "        data = json_data\n",
    "\n",
    "    # Document 객체를 저장할 리스트\n",
    "    documents = []\n",
    "\n",
    "    # JSON 데이터에서 choices를 추출\n",
    "    choices = data.get(\"choices\", [])\n",
    "    if not choices:\n",
    "        raise ValueError(\"JSON 데이터에 'choices' 키가 없습니다.\")\n",
    "\n",
    "    # 각 choice에서 reference_documents를 추출\n",
    "    for choice in choices:\n",
    "        reference_docs = choice.get(\"reference_documents\", [])\n",
    "        for ref_doc in reference_docs:\n",
    "            # page_content와 metadata 추출\n",
    "            page_content = ref_doc.get(\"page_content\", \"\")\n",
    "            metadata = ref_doc.get(\"metadata\", {})\n",
    "\n",
    "            # Document 객체 생성\n",
    "            doc = Document(\n",
    "                page_content=page_content,\n",
    "                metadata=metadata\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "    if not documents:\n",
    "        raise ValueError(\"변환된 Document 객체가 없습니다. JSON 데이터에 'reference_documents'가 포함되어 있는지 확인하세요.\")\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d2bde",
   "metadata": {},
   "source": [
    "\"CLOUD_API_KEY\"는 IBM Cloud의 watsonx 서비스에서 API KEY 정보를 가져옵니다.   \n",
    "\"MY_PROJECT_ID\"는 IBM Cloud의 watsonx 서비스에서 프로젝트 ID 정보를 가져옵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd37b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM Cloud API Key와 URL 설정\n",
    "api_key = \"<CLOUD_API_KEY>\"\n",
    "# region에 따라 주소가 다를 수 있습니다. 주소를 확인해 주세요.\n",
    "ibm_cloud_url = \"https://us-south.ml.cloud.ibm.com\" \n",
    "project_id = \"<MY_PROJECT_ID>\"\n",
    "\n",
    "# 배포한 AutoAI RAG 모델의 URL\n",
    "auto_ai_rag_url = \"<IBM_AUTOAI_RAG_URL>\"\n",
    "auto_ai_rag_stream_url = \"<IBM_AUTOAI_RAG_STREAM_URL>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4ea44",
   "metadata": {},
   "source": [
    "이 셀에서는 사용자 입력을 설정합니다. `user_input` 변수에 질문을 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddfbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = '기업의 생성형AI 도입 현황은?'\n",
    "# user_input = \"기업에서 생성형 AI를 도입하는 가치는?\"\n",
    "# user_input = \"기업에서 생성형 AI를 도입하기 위해 고려사항은?\"\n",
    "# user_input = \"기업에서 생성형 AI 도입을 가로막는 가장 큰 장애물은?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ce3cc",
   "metadata": {},
   "source": [
    "이 셀에서는 IBM Cloud API를 사용하여 인증 토큰을 가져오고, AutoAI RAG 서비스에 요청을 보내 응답을 스트리밍 방식으로 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# IBM Cloud API Key를 사용하여 토큰 발급\n",
    "token_response = requests.post(\n",
    "    'https://iam.cloud.ibm.com/identity/token',\n",
    "    data={\n",
    "        \"apikey\": api_key,\n",
    "        \"grant_type\": 'urn:ibm:params:oauth:grant-type:apikey'\n",
    "    }\n",
    ")\n",
    "mltoken = token_response.json().get(\"access_token\")\n",
    "if not mltoken:\n",
    "    raise Exception(\"토큰 발급 실패!\")\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {mltoken}',\n",
    "    'Accept': 'text/event-stream'  # 스트리밍 응답 처리용 헤더\n",
    "}\n",
    "\n",
    "payload_scoring = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    auto_ai_rag_url,\n",
    "    headers=headers,\n",
    "    json=payload_scoring,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"=== 응답 결과 ===\")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00704f",
   "metadata": {},
   "source": [
    "# IBM AutoAI RAG 서비스와 Rangchain을 통합한 시스템 구현\n",
    "\n",
    "LangChain은 다양한 데이터 소스와 AI 모델을 연결하여 Retrieval-Augmented Generation(RAG) 시스템을 구축하는 데 유용한 라이브러리입니다. RAG는 검색 기반 접근 방식을 활용하여 대규모 언어 모델(LLM)의 성능을 향상시키는 기술입니다. \n",
    "\n",
    "여기서는 IBM AutoAI RAG 서비스의 강력한 데이터 처리 기능과 LangChain의 유연한 체인 구성 기능을 결합하여 RAG 시스템을 구현하는 방법을 다룹니다. 이를 통해 다음과 같은 작업을 수행할 수 있습니다:\n",
    "- IBM AutoAI RAG 데이터 소스에서 정보를 검색\n",
    "- 검색된 정보를 기반으로 LLM을 활용하여 질문에 대한 답변 생성\n",
    "- LangChain을 사용하여 체인을 구성하고, 데이터 소스와 AI 모델 간의 상호작용을 관리\n",
    "\n",
    "이 시스템은 기업이 생성형 AI를 활용하여 노코드 기반의 AI RAG 서비스를 생성하고, RagChain을 통해 이를 통합하여 다양한 비즈니스 문제를 해결하는 데 도움을 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5bab17",
   "metadata": {},
   "source": [
    "## IBM AutoAI RAG 모델을 사용하여 문서 검색\n",
    "IBM watsonx.ai에 배포된 AutoAI 기반 RAG 서비스를 활용하여 문서 검색과 질의 응답을 수행합니다. IBM에서 제공하는 SDK를 이용해 AI 서비스를 호출하며, 사용자의 질문을 전달하면 AutoAI RAG 서비스는 답변과 함께 관련 문서 목록도 함께 반환합니다. 이를 위해  ```call_ai_service``` 함수를 정의하여 AI 서비스 호출, 응답 처리, 관련 문서 추출을 일괄적으로 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d183c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def call_ai_service (user_input):\n",
    "\n",
    "    # IBM Cloud API Key를 사용하여 토큰 발급\n",
    "    token_response = requests.post(\n",
    "        'https://iam.cloud.ibm.com/identity/token',\n",
    "        data={\n",
    "            \"apikey\": api_key,\n",
    "            \"grant_type\": 'urn:ibm:params:oauth:grant-type:apikey'\n",
    "        }\n",
    "    )\n",
    "    mltoken = token_response.json().get(\"access_token\")\n",
    "    if not mltoken:\n",
    "        raise Exception(\"토큰 발급 실패!\")\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {mltoken}',\n",
    "        'Accept': 'text/event-stream'  # 스트리밍 응답 처리용 헤더\n",
    "    }\n",
    "    \n",
    "    payload_scoring = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        auto_ai_rag_url,\n",
    "        headers=headers,\n",
    "        json=payload_scoring,\n",
    "        stream=True\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c39e44",
   "metadata": {},
   "source": [
    "## IBM watsonx.ai 모델 설정\n",
    "watsionx.ai는 IBM의 AI 플랫폼으로, 다양한 AI 모델과 서비스를 제공합니다. 아래 코드는 watsonx.ai 모델을 사용할 수 있도록 watsonx.ai의 AI 모델에 연결합니다.\n",
    "* 모델 파라미터 설정\n",
    "* 모델 이름 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"WATSONX_URL\"] = ibm_cloud_url\n",
    "os.environ[\"WATSONX_APIKEY\"] = api_key\n",
    "# os.environ[\"WATSONX_TOKEN\"] = \"\"\n",
    "\n",
    "# 모델 파라미터 설정\n",
    "params = {\n",
    "    \"decoding_method\": \"greedy\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"min_new_tokens\": 50,\n",
    "    \"max_new_tokens\": 1000\n",
    "}\n",
    "\n",
    "# WatsonxLLM 모델 초기화\n",
    "model_llm = WatsonxLLM(\n",
    "    model_id=\"meta-llama/llama-3-3-70b-instruct\",  # 모델 이름 설정\n",
    "    project_id=project_id,\n",
    "    params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef60c3c",
   "metadata": {},
   "source": [
    "## LangChain을 사용하여 AI 서비스와 통합\n",
    "LangChain을 사용하여 IBM AutoAI RAG 서비스와 통합하여 RAG 시스템을 구축합니다. LangChain의 `create_stuff_documents_chain` 체인을 사용하여 검색 기반 질의 응답 시스템을 구현합니다. 이 체인은 검색기와 LLM을 결합하여 사용자의 질문에 대한 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a0d06",
   "metadata": {},
   "source": [
    "배포한 Auto RAG AI 서비스에서 데이터를 검색 후 Langchain과 연동하기 위해 데이타 타입을 Document 형식으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80491569",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = '기업의 생성형AI 도입 현황은?'\n",
    "# user_input = \"기업에서 생성형 AI를 도입하는 가치는?\"\n",
    "# user_input = \"기업에서 생성형 AI를 도입하기 위해 고려사항은?\"\n",
    "# user_input = \"기업에서 생성형 AI 도입을 가로막는 가장 큰 장애물은?\"\n",
    "\n",
    "\n",
    "reference_docs = call_ai_service(user_input)\n",
    "# 변환된 문서 리스트\n",
    "docs_search = convert_to_documents(reference_docs.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d231f3",
   "metadata": {},
   "source": [
    "watsonx에 배포한 AI 서비스의 응답 결과를 Langchain과 결합하여 RAG 시스템을 구축할 수 있습니다. Langchain은 다양한 데이터 소스와 AI 모델을 연결하여 RAG 시스템을 구축하는 데 유용한 라이브러리입니다. Langchain을 사용하면 데이터 소스에서 정보를 검색하고, AI 모델을 사용하여 새로운 텍스트를 생성하는 작업을 쉽게 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 정의\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "아래 문서를 참고해서 사용자 질문에 정확하게 한국어로 답변해줘.  \n",
    "- 주어진 질문에 대한 답변만 제공하고, 추가적인 질문이나 답변은 절대 생성하지 마.  \n",
    "- 답변은 간결하게 3문장 이내로 작성하며, 문서에 기반한 사실만 포함해.\n",
    "\n",
    "문서:\n",
    "{context}\n",
    "\n",
    "질문: {input}\n",
    "\n",
    "답변:\n",
    "\"\"\")\n",
    "\n",
    "# 문서 체인 구성\n",
    "stuff_chain = create_stuff_documents_chain(model_llm, prompt)\n",
    "\n",
    "\n",
    "# 실행\n",
    "result = stuff_chain.invoke({\"context\": docs_search, \"input\":user_input})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
